import streamlit as st
import speech_recognition as sr
from difflib import SequenceMatcher
import numpy as np
from datetime import datetime
import threading
import time
import pyaudio
import wave

class AudioRecorder:
    def __init__(self):
        self.is_recording = False
        self.is_paused = False
        self.frames = []
        self.audio = pyaudio.PyAudio()
        self.stream = None
        
    def start_recording(self):
        """ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤."""
        self.frames = []
        self.is_recording = True
        self.is_paused = False
        
        def record():
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=44100,
                input=True,
                frames_per_buffer=1024
            )
            
            while self.is_recording:
                if not self.is_paused:
                    data = self.stream.read(1024)
                    self.frames.append(data)
                else:
                    time.sleep(0.1)
                    
        self.record_thread = threading.Thread(target=record)
        self.record_thread.start()
        
    def pause_recording(self):
        """ë…¹ìŒì„ ì¼ì‹œì¤‘ì§€í•©ë‹ˆë‹¤."""
        self.is_paused = True
        
    def resume_recording(self):
        """ë…¹ìŒì„ ì¬ê°œí•©ë‹ˆë‹¤."""
        self.is_paused = False
        
    def stop_recording(self):
        """ë…¹ìŒì„ ì¢…ë£Œí•˜ê³  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."""
        self.is_recording = False
        self.record_thread.join()
        
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        
        # ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥
        wf = wave.open("temp_recording.wav", 'wb')
        wf.setnchannels(1)
        wf.setsampwidth(self.audio.get_sample_size(pyaudio.paInt16))
        wf.setframerate(44100)
        wf.writeframes(b''.join(self.frames))
        wf.close()
        
        return "temp_recording.wav"

def calculate_similarity(text1, text2):
    """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    return SequenceMatcher(None, text1, text2).ratio()

def get_feedback(student_answer, model_answer, similarity_threshold=0.7):
    """í•™ìƒì˜ ë‹µë³€ì„ ë¶„ì„í•˜ê³  í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    similarity = calculate_similarity(student_answer.lower(), model_answer.lower())
    
    feedback = {
        "similarity": round(similarity * 100, 2),
        "strengths": [],
        "improvements": []
    }
    
    model_keywords = set(model_answer.lower().split())
    student_keywords = set(student_answer.lower().split())
    
    used_keywords = student_keywords.intersection(model_keywords)
    missing_keywords = model_keywords - student_keywords
    
    if similarity >= similarity_threshold:
        feedback["strengths"].append("ë‹µë³€ì´ ëª¨ë²” ë‹µì•ˆê³¼ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤.")
        feedback["strengths"].append(f"í•µì‹¬ í‚¤ì›Œë“œ {len(used_keywords)}ê°œë¥¼ ì˜ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.")
    else:
        feedback["improvements"].append("ë‹µë³€ì˜ êµ¬ì¡°ë¥¼ ëª¨ë²” ë‹µì•ˆê³¼ ë” ìœ ì‚¬í•˜ê²Œ ê°œì„ í•´ë³´ì„¸ìš”.")
        
    if missing_keywords:
        feedback["improvements"].append(f"ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì„ í¬í•¨ì‹œì¼œë³´ì„¸ìš”: {', '.join(missing_keywords)}")
    
    return feedback

def process_audio_file(file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    recognizer = sr.Recognizer()
    with sr.AudioFile(file_path) as source:
        audio = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio, language='ko-KR')
            return text
        except sr.UnknownValueError:
            st.error("ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return None
        except sr.RequestError:
            st.error("ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

def main():
    st.title("ğŸ¤ ìŒì„± ê¸°ë°˜ í•™ìŠµ í”¼ë“œë°± ì‹œìŠ¤í…œ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'history' not in st.session_state:
        st.session_state.history = []
    if 'recorder' not in st.session_state:
        st.session_state.recorder = None
    if 'recording_state' not in st.session_state:
        st.session_state.recording_state = "stopped"  # "stopped", "recording", "paused"
    
    # ì‚¬ì´ë“œë°”ì— ëª¨ë²” ë‹µì•ˆ ì…ë ¥
    with st.sidebar:
        st.header("ğŸ“ ëª¨ë²” ë‹µì•ˆ ì„¤ì •")
        model_answer = st.text_area(
            "ëª¨ë²” ë‹µì•ˆì„ ì…ë ¥í•˜ì„¸ìš”:",
            value="ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥ê³¼ ì¶”ë¡ ëŠ¥ë ¥, ì§€ê°ëŠ¥ë ¥, ìì—°ì–¸ì–´ì˜ ì´í•´ëŠ¥ë ¥ ë“±ì„ ì»´í“¨í„° í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì‹¤í˜„í•œ ê¸°ìˆ ì…ë‹ˆë‹¤."
        )
        
        st.header("âš™ï¸ ì„¤ì •")
        similarity_threshold = st.slider(
            "ìœ ì‚¬ë„ ì„ê³„ê°’",
            min_value=0.0,
            max_value=1.0,
            value=0.7,
            help="ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§ˆ ë•Œ ë‹µë³€ì´ ì¶©ë¶„íˆ ìœ ì‚¬í•˜ë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤."
        )
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns(2)
    
    with col1:
        st.header("ğŸ™ï¸ ìŒì„± ë…¹ìŒ")
        
        # ë…¹ìŒ ì»¨íŠ¸ë¡¤ ë²„íŠ¼ë“¤
        col_rec, col_pause, col_stop = st.columns(3)
        
        with col_rec:
            if st.button("ë…¹ìŒ ì‹œì‘", disabled=st.session_state.recording_state == "recording"):
                st.session_state.recorder = AudioRecorder()
                st.session_state.recorder.start_recording()
                st.session_state.recording_state = "recording"
                st.rerun()
        
        with col_pause:
            if st.button("ì¼ì‹œì •ì§€", disabled=st.session_state.recording_state not in ["recording", "paused"]):
                if st.session_state.recording_state == "recording":
                    st.session_state.recorder.pause_recording()
                    st.session_state.recording_state = "paused"
                else:
                    st.session_state.recorder.resume_recording()
                    st.session_state.recording_state = "recording"
                st.rerun()
        
        with col_stop:
            if st.button("ë…¹ìŒ ì¢…ë£Œ", disabled=st.session_state.recording_state == "stopped"):
                if st.session_state.recorder:
                    audio_file = st.session_state.recorder.stop_recording()
                    student_answer = process_audio_file(audio_file)
                    
                    if student_answer:
                        st.success("ìŒì„±ì´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # í”¼ë“œë°± ìƒì„±
                        feedback = get_feedback(student_answer, model_answer, similarity_threshold)
                        
                        # ê¸°ë¡ ì €ì¥
                        st.session_state.history.append({
                            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "student_answer": student_answer,
                            "feedback": feedback
                        })
                        
                        # ê²°ê³¼ í‘œì‹œ
                        st.write("### ë‹¹ì‹ ì˜ ë‹µë³€:")
                        st.write(student_answer)
                        
                        st.write(f"### ìœ ì‚¬ë„: {feedback['similarity']}%")
                        
                        if feedback['strengths']:
                            st.write("### ì˜í•œ ì  ğŸ‘")
                            for strength in feedback['strengths']:
                                st.write(f"- {strength}")
                        
                        if feedback['improvements']:
                            st.write("### ê°œì„ í•  ì  ğŸ’ª")
                            for improvement in feedback['improvements']:
                                st.write(f"- {improvement}")
                    
                    st.session_state.recording_state = "stopped"
                    st.session_state.recorder = None
                    st.rerun()
        
        # í˜„ì¬ ë…¹ìŒ ìƒíƒœ í‘œì‹œ
        if st.session_state.recording_state == "recording":
            st.write("ğŸ”´ ë…¹ìŒ ì¤‘...")
        elif st.session_state.recording_state == "paused":
            st.write("â¸ï¸ ì¼ì‹œì •ì§€ë¨")
    
    with col2:
        st.header("ğŸ“Š í•™ìŠµ ê¸°ë¡")
        if st.session_state.history:
            for entry in reversed(st.session_state.history):
                with st.expander(f"ğŸ“ {entry['timestamp']}"):
                    st.write("**ë‹µë³€:**")
                    st.write(entry['student_answer'])
                    st.write(f"**ìœ ì‚¬ë„:** {entry['feedback']['similarity']}%")
                    
                    if entry['feedback']['strengths']:
                        st.write("**ì˜í•œ ì :**")
                        for strength in entry['feedback']['strengths']:
                            st.write(f"- {strength}")
                    
                    if entry['feedback']['improvements']:
                        st.write("**ê°œì„ í•  ì :**")
                        for improvement in entry['feedback']['improvements']:
                            st.write(f"- {improvement}")
        else:
            st.info("ì•„ì§ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹µë³€ì„ ë…¹ìŒí•´ë³´ì„¸ìš”!")

if __name__ == "__main__":
    main()